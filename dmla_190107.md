#신보센세 graph_NN 소개
##Knowledge Graphs(KG)
- 노드: 엔티티
##엠베딩 방법
- 엔티티를 공간의 점으로 표현
- 노드 사이의 관계는 벡터로 표현(벡터가 아닐 수도 있다)
- 다차원에 원점에서부터 벡터의 방향이 같은지(모아져 있는지)로 엔티티 집합을 알 수 있다.
##Geometry of Embeddings
- Mimno and Thomson 2017
- 엔티티와 관계 벡터가 주어졌을 때 스코어 함수를 만들 수 있는데 이를 학습해야 하기 때문에 엠베딩을 만드는 것이 중요하다.
- correct triples T
- 로스함수는 로지스틱에서 사용하는 것
### additive method
- M: transE(Bordes et al., 2013) / transR(Lin et al., 2015) / STransE(Nguyen et al., 2016)
- 관계 벡터 r
- 거리가 가까울수록 스코어가 높아짐
- 엔티티 벡터도 학
### multiplicative method
- DisMult(Yang et al., 2014)
- HolE(Nickel et al., 2016)
- ComplEx(Trouillon et al., 2016): A와 B의 부모는 누구이다 == B와 A의 부모는 누구이다 를 가능하게 하기 위해
###neural method
- 어려
###Geometrical Metrics
- average vector length: 엔티티 사이의 거리 평균을 구함
- alignment to mean: 엔티티 집합의 센트로이드(벡터 집합의 중심점)와 v의 코사인 거리를 구함
- concity: 개개의 엔티티에는 관심 없음. Conicity(V)의 값이 크면 벡터가 모여있는거고 작으면 퍼져있는 것이다.
- vector spread: ATM에서 conicity를 빼서 제곱한 값의 합의 평균? 분산?
##문제
- 엠베딩 방법에 따라 결과가 달라짐
- 하이퍼파라메터의 영향(네거티브 샘플링으로 인한 영향)
- 상관관계...?

## 의논점
- "네거티브 샘플링을 늘린다는 소리는 공기 정도가 어느 정도 이상인 것 외에는 취급하지 않는 것 아닌가?"
- "그러면 그냥 내적만 커다란 결과가 되어버리는 것 아닌가"
- 차원을 줄이면 conicity가 줄어듬
- "네거티브 샘플링을 늘리면 slope가 급격해짐..? 근데 conicity랑 관계없는 결과라고 보는데."
- 어쨌든 네거티브 샘플링과 conicity의 상관관계에 대한 의논이 계속됨